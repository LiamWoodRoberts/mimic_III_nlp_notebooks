{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a BiLSTM for NER \n",
    "\n",
    "## Using an Annotated DataTurks .tsv File\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from seqeval.metrics import f1_score,classification_report\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional,Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting Data to Sequences\n",
    "\n",
    "### Contents:\n",
    "\n",
    "1. Reading File and formatting as sequences\n",
    "2. Formatting Entities to IOB Scheme\n",
    "3. Padding Sequences\n",
    "4. Mapping to Integer Ids\n",
    "5. Train Test Split\n",
    "6. Specifying Model and Model Parameters\n",
    "7. Training Model\n",
    "8. Evaluating Model Performance\n",
    "9. Saving Results\n",
    "\n",
    "### 1. Reading and Formatting File:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_turks(file):\n",
    "    with open(file) as f:\n",
    "        lines = [i.rstrip().split(\"\\t\") for i in f.readlines()]\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0,\"HISTORY', 'O'],\n",
       " ['OF', 'O'],\n",
       " ['PRESENT', 'O'],\n",
       " ['ILLNESS', 'O'],\n",
       " ['This', 'O'],\n",
       " ['is', 'O'],\n",
       " ['an', 'O'],\n",
       " ['81-year-old', 'CONDITION/SYMPTOM'],\n",
       " ['female', 'CONDITION/SYMPTOM'],\n",
       " ['with', 'O'],\n",
       " ['a', 'O'],\n",
       " ['history', 'O'],\n",
       " ['of', 'O'],\n",
       " ['emphysema', 'CONDITION/SYMPTOM'],\n",
       " ['not', 'O'],\n",
       " ['on', 'O'],\n",
       " ['home', 'DRUG'],\n",
       " ['O2', 'DRUG'],\n",
       " [',', 'O'],\n",
       " ['who', 'O']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"./nlp_data/Medical NER Dataset 2600.tsv\"\n",
    "word_ents = read_turks(file)\n",
    "word_ents[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_words(word_ents):\n",
    "    '''removes quote and comma characters from '''\n",
    "    new_word_ents = []\n",
    "    for ents in word_ents:\n",
    "        word = ents[0].lower()\n",
    "        if word.find(',') > 0:\n",
    "            word = word[word.find(',')+1:]\n",
    "        word = word.replace('\"','')\n",
    "        ents[0] = word\n",
    "        new_word_ents.append(ents)\n",
    "    return new_word_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['history', 'O'],\n",
       " ['of', 'O'],\n",
       " ['present', 'O'],\n",
       " ['illness', 'O'],\n",
       " ['this', 'O'],\n",
       " ['is', 'O'],\n",
       " ['an', 'O'],\n",
       " ['81-year-old', 'CONDITION/SYMPTOM'],\n",
       " ['female', 'CONDITION/SYMPTOM'],\n",
       " ['with', 'O'],\n",
       " ['a', 'O'],\n",
       " ['history', 'O'],\n",
       " ['of', 'O'],\n",
       " ['emphysema', 'CONDITION/SYMPTOM'],\n",
       " ['not', 'O'],\n",
       " ['on', 'O'],\n",
       " ['home', 'DRUG'],\n",
       " ['o2', 'DRUG'],\n",
       " [',', 'O'],\n",
       " ['who', 'O']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ents = clean_words(word_ents)\n",
    "new_ents[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seqs(word_ents):\n",
    "    seqs = []\n",
    "    seq = []\n",
    "    for ents in word_ents:\n",
    "        if len(ents)>1:\n",
    "            if len(ents[0])>1:\n",
    "                seq.append(ents)\n",
    "        else:\n",
    "            seqs.append(seq)\n",
    "            seq=[]\n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['history', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['present', 'O'],\n",
       "  ['illness', 'O'],\n",
       "  ['this', 'O'],\n",
       "  ['is', 'O'],\n",
       "  ['an', 'O'],\n",
       "  ['81-year-old', 'CONDITION/SYMPTOM'],\n",
       "  ['female', 'CONDITION/SYMPTOM'],\n",
       "  ['with', 'O'],\n",
       "  ['history', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['emphysema', 'CONDITION/SYMPTOM'],\n",
       "  ['not', 'O'],\n",
       "  ['on', 'O'],\n",
       "  ['home', 'DRUG'],\n",
       "  ['o2', 'DRUG'],\n",
       "  ['who', 'O'],\n",
       "  ['presents', 'O'],\n",
       "  ['with', 'O'],\n",
       "  ['three', 'AMOUNT'],\n",
       "  ['days', 'AMOUNT'],\n",
       "  ['of', 'O'],\n",
       "  ['shortness', 'CONDITION/SYMPTOM'],\n",
       "  ['of', 'CONDITION/SYMPTOM'],\n",
       "  ['breath', 'CONDITION/SYMPTOM'],\n",
       "  ['thought', 'O'],\n",
       "  ['by', 'O'],\n",
       "  ['her', 'O'],\n",
       "  ['primary', 'O'],\n",
       "  ['care', 'O'],\n",
       "  ['doctor', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['be', 'O'],\n",
       "  ['copd', 'CONDITION/SYMPTOM'],\n",
       "  ['flare', 'CONDITION/SYMPTOM']]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = create_seqs(new_ents)\n",
    "seqs[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Formatting Entities to IOB (Inside,Outside, Beginning) Scheme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tags(word_ents):\n",
    "    '''adds IOB scheme to tags'''\n",
    "    new_ents = []\n",
    "    for i in range(0,len(word_ents)):\n",
    "        if word_ents[i][1] == \"O\":\n",
    "            tag = word_ents[i][1]\n",
    "        else:\n",
    "            if not i:\n",
    "                tag = \"B-\"+word_ents[i][1]\n",
    "            else:\n",
    "                if (word_ents[i][1] != word_ents[i-1][1]):\n",
    "                    tag = \"B-\"+word_ents[i][1]\n",
    "                else:\n",
    "                    tag = \"I-\"+word_ents[i][1]\n",
    "\n",
    "        new_ents.append([word_ents[i][0],tag])\n",
    "    return new_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['in', 'O'],\n",
       " ['the', 'O'],\n",
       " ['hospital3', 'O'],\n",
       " ['emergency', 'O'],\n",
       " ['her', 'O'],\n",
       " ['oxygen', 'B-MEASUREMENT'],\n",
       " ['saturation', 'I-MEASUREMENT'],\n",
       " ['was', 'I-MEASUREMENT'],\n",
       " ['100%', 'I-MEASUREMENT'],\n",
       " ['on', 'O'],\n",
       " ['cpap', 'O']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_tag_seqs = [clean_tags(ents) for ents in seqs]\n",
    "cleaned_tag_seqs[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Padding Sequences to a Specified Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_seq(seq,max_len):\n",
    "    padded_seq = seq+[[\"<PAD>\",\"O\"]]*max_len\n",
    "    return padded_seq[:max_len]\n",
    "    \n",
    "def pad_sequences(sequences,max_len=None):\n",
    "    if max_len == None:\n",
    "        max_len = max(len(seq) for seq in sequences)\n",
    "    return [pad_seq(seq,max_len) for seq in sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['two', 'B-TIME'],\n",
       " ['days', 'I-TIME'],\n",
       " ['prior', 'I-TIME'],\n",
       " ['to', 'I-TIME'],\n",
       " ['admission', 'I-TIME'],\n",
       " ['she', 'O'],\n",
       " ['was', 'O'],\n",
       " ['started', 'O'],\n",
       " ['on', 'O'],\n",
       " ['prednisone', 'B-DRUG'],\n",
       " ['taper', 'O'],\n",
       " ['and', 'O'],\n",
       " ['one', 'B-TIME'],\n",
       " ['day', 'I-TIME'],\n",
       " ['prior', 'I-TIME'],\n",
       " ['to', 'I-TIME'],\n",
       " ['admission', 'I-TIME'],\n",
       " ['she', 'O'],\n",
       " ['required', 'O'],\n",
       " ['oxygen', 'B-DRUG'],\n",
       " ['at', 'O'],\n",
       " ['home', 'O'],\n",
       " ['in', 'O'],\n",
       " ['order', 'O'],\n",
       " ['to', 'O'],\n",
       " ['maintain', 'O'],\n",
       " ['oxygen', 'B-MEASUREMENT'],\n",
       " ['saturation', 'I-MEASUREMENT'],\n",
       " ['greater', 'I-MEASUREMENT'],\n",
       " ['than', 'I-MEASUREMENT'],\n",
       " ['90%', 'I-MEASUREMENT'],\n",
       " ['<PAD>', 'O'],\n",
       " ['<PAD>', 'O'],\n",
       " ['<PAD>', 'O'],\n",
       " ['<PAD>', 'O'],\n",
       " ['<PAD>', 'O'],\n",
       " ['<PAD>', 'O'],\n",
       " ['<PAD>', 'O'],\n",
       " ['<PAD>', 'O'],\n",
       " ['<PAD>', 'O'],\n",
       " ['<PAD>', 'O'],\n",
       " ['<PAD>', 'O'],\n",
       " ['<PAD>', 'O'],\n",
       " ['<PAD>', 'O'],\n",
       " ['<PAD>', 'O'],\n",
       " ['<PAD>', 'O'],\n",
       " ['<PAD>', 'O'],\n",
       " ['<PAD>', 'O'],\n",
       " ['<PAD>', 'O'],\n",
       " ['<PAD>', 'O']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seqs = pad_sequences(cleaned_tag_seqs,max_len=50)\n",
    "padded_seqs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Mapping Words to Integer Values for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_ids(sentances,tag=False):\n",
    "    words = []\n",
    "    for sentance in sentances:\n",
    "        words += list([word[tag] for word in sentance])\n",
    "    word_dict = {word:i for i,word in enumerate(set(words))}\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2112-6-5', 0), ('requiring', 1), ('gastric', 2), ('guaiac-positive', 3)]\n",
      "[('B-EVENT', 0), ('B-DRUG', 1), ('I-TIME', 2), ('B-FREQUENCY', 3)]\n"
     ]
    }
   ],
   "source": [
    "word_ids = get_word_ids(padded_seqs)\n",
    "tag_ids = get_word_ids(padded_seqs,tag=True)\n",
    "print(list(word_ids.items())[:4])\n",
    "print(list(tag_ids.items())[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_ids(sentances,word_ids,tag_ids):\n",
    "    vector = []\n",
    "    for sentance in sentances:\n",
    "        vector.append(list([[word_ids[w[0]],tag_ids[w[1]]] for w in sentance]))\n",
    "    return np.array(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5249   17]\n",
      " [4326   17]\n",
      " [4055   17]\n",
      " [5145   17]]\n",
      "\n",
      "Word Representation:\n",
      "[['history', 'O'], ['of', 'O'], ['present', 'O'], ['illness', 'O']]\n"
     ]
    }
   ],
   "source": [
    "vectors = words_to_ids(padded_seqs,word_ids,tag_ids)\n",
    "print(vectors[0][:4])\n",
    "print('')\n",
    "print(\"Word Representation:\")\n",
    "print(padded_seqs[0][:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_x_y(matrix,n_tags):\n",
    "    x = []\n",
    "    y = []\n",
    "    for sequences in matrix:\n",
    "        xi = [i[0] for i in sequences]\n",
    "        yi = [i[1] for i in sequences]\n",
    "        x.append(xi)\n",
    "        y.append(yi)\n",
    "    y = np.array([to_categorical(i,n_tags) for i in y])\n",
    "    return np.array(x),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-shape: (2592, 50)\n",
      "[5249 4326 4055 5145 2359]\n",
      "\n",
      "Y-shape: (2592, 50, 23)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "n_tags = len(tag_ids)\n",
    "x,y = create_x_y(vectors,n_tags)\n",
    "print(\"X-shape:\",x.shape)\n",
    "print(x[0][:5])\n",
    "print('')\n",
    "print(\"Y-shape:\",y.shape)\n",
    "print(y[0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Specifying Model and Model Parameters\n",
    "\n",
    "https://www.depends-on-the-definition.com/introduction-named-entity-recognition-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_BiLSTM(n_words,n_tags,embedding_size,max_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(n_words,embedding_size,input_length=max_len))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.2)))\n",
    "    model.add(TimeDistributed(Dense(n_tags, activation=\"softmax\")))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 50, 100)           530000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50, 100)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 50, 200)           160800    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 50, 23)            4623      \n",
      "=================================================================\n",
      "Total params: 695,423\n",
      "Trainable params: 695,423\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "max_len = 50\n",
    "embedding_size = 100\n",
    "n_words = len(word_ids)\n",
    "n_tags = len(tag_ids)\n",
    "\n",
    "model = create_BiLSTM(n_words,n_tags,embedding_size,max_len)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_model(model,x_train,y_train,batch_size=32,epochs=20,val_split = 0.1):\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss',\n",
    "                               min_delta=0.0001,\n",
    "                               patience=3,\n",
    "                               mode='min',\n",
    "                               verbose=1)\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    history = model.fit(x_train, y_train, \n",
    "                        batch_size=32, \n",
    "                        epochs=epochs, \n",
    "                        validation_split=val_split, \n",
    "                        verbose=1,\n",
    "                        callbacks=[early_stop]\n",
    "                       )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2098 samples, validate on 234 samples\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From /Users/LiamRoberts/anaconda3/envs/keras36/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1394: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x1a3b4ccb70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x1a3b4ccb70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "2098/2098 [==============================] - 16s 8ms/sample - loss: 0.6930 - accuracy: 0.8506 - val_loss: 0.5318 - val_accuracy: 0.8612\n",
      "Epoch 2/50\n",
      "2098/2098 [==============================] - 12s 6ms/sample - loss: 0.4775 - accuracy: 0.8694 - val_loss: 0.4440 - val_accuracy: 0.8752\n",
      "Epoch 3/50\n",
      "2098/2098 [==============================] - 11s 5ms/sample - loss: 0.3994 - accuracy: 0.8902 - val_loss: 0.3979 - val_accuracy: 0.8881\n",
      "Epoch 4/50\n",
      "2098/2098 [==============================] - 11s 5ms/sample - loss: 0.3508 - accuracy: 0.9021 - val_loss: 0.3644 - val_accuracy: 0.8932\n",
      "Epoch 5/50\n",
      "2098/2098 [==============================] - 11s 5ms/sample - loss: 0.3067 - accuracy: 0.9133 - val_loss: 0.3361 - val_accuracy: 0.9012\n",
      "Epoch 6/50\n",
      "2098/2098 [==============================] - 16s 8ms/sample - loss: 0.2674 - accuracy: 0.9236 - val_loss: 0.3094 - val_accuracy: 0.9095\n",
      "Epoch 7/50\n",
      "2098/2098 [==============================] - 16s 8ms/sample - loss: 0.2381 - accuracy: 0.9319 - val_loss: 0.2911 - val_accuracy: 0.9140\n",
      "Epoch 8/50\n",
      "2098/2098 [==============================] - 16s 8ms/sample - loss: 0.2135 - accuracy: 0.9385 - val_loss: 0.2783 - val_accuracy: 0.9189\n",
      "Epoch 9/50\n",
      "2098/2098 [==============================] - 16s 7ms/sample - loss: 0.1928 - accuracy: 0.9442 - val_loss: 0.2702 - val_accuracy: 0.9212\n",
      "Epoch 10/50\n",
      "2098/2098 [==============================] - 17s 8ms/sample - loss: 0.1763 - accuracy: 0.9494 - val_loss: 0.2606 - val_accuracy: 0.9241\n",
      "Epoch 11/50\n",
      "2098/2098 [==============================] - 15s 7ms/sample - loss: 0.1612 - accuracy: 0.9531 - val_loss: 0.2572 - val_accuracy: 0.9266\n",
      "Epoch 12/50\n",
      "2098/2098 [==============================] - 16s 8ms/sample - loss: 0.1480 - accuracy: 0.9568 - val_loss: 0.2524 - val_accuracy: 0.9269\n",
      "Epoch 13/50\n",
      "2098/2098 [==============================] - 17s 8ms/sample - loss: 0.1379 - accuracy: 0.9591 - val_loss: 0.2544 - val_accuracy: 0.9285\n",
      "Epoch 14/50\n",
      "2098/2098 [==============================] - 15s 7ms/sample - loss: 0.1276 - accuracy: 0.9617 - val_loss: 0.2533 - val_accuracy: 0.9296\n",
      "Epoch 15/50\n",
      "2098/2098 [==============================] - 15s 7ms/sample - loss: 0.1188 - accuracy: 0.9640 - val_loss: 0.2596 - val_accuracy: 0.9280\n",
      "Epoch 00015: early stopping\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 32\n",
    "history = train_model(model,x_train,y_train,batch_size=batch_size,epochs=epochs,val_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_mappings(ids):\n",
    "    return {str(i[1]):i[0] for i in ids.items()}\n",
    "\n",
    "def generate_sample(x,y,model):\n",
    "    idx = random.randint(0,len(x))\n",
    "    sample = x[idx]\n",
    "    label = np.argmax(y[idx],axis=1)\n",
    "\n",
    "    p = model.predict(sample.reshape(1,-1))\n",
    "    p = np.argmax(p,axis=-1)\n",
    "    print(\"{:25} {:20}: {:10}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "    print(\"-\"*50)\n",
    "    for i in range(len(sample)):\n",
    "        word = str(sample[i])\n",
    "        pred = str(p[0][i])\n",
    "        true_val = str(label[i])\n",
    "        id_to_words = get_id_mappings(word_ids)\n",
    "        id_to_tags = get_id_mappings(tag_ids)\n",
    "        print(f\"{id_to_words[word]:25}{id_to_tags[true_val]:20}{id_to_tags[pred]}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                      True                : Pred      \n",
      "--------------------------------------------------\n",
      "she                      O                   O\n",
      "followed                 O                   O\n",
      "up                       O                   O\n",
      "with                     O                   O\n",
      "the                      O                   O\n",
      "cardiologist             B-ORGANIZATION      B-ORGANIZATION\n",
      "np                       I-ORGANIZATION      B-TIME\n",
      "one                      B-TIME              B-TIME\n",
      "week                     I-TIME              I-TIME\n",
      "later                    I-TIME              I-TIME\n",
      "and                      O                   O\n",
      "was                      O                   O\n",
      "found                    O                   O\n",
      "to                       O                   O\n",
      "have                     O                   O\n",
      "o2sats                   B-MEASUREMENT       B-MEASUREMENT\n",
      "ranging                  I-MEASUREMENT       I-MEASUREMENT\n",
      "from                     I-MEASUREMENT       I-MEASUREMENT\n",
      "68-80%                   I-MEASUREMENT       I-MEASUREMENT\n",
      "on                       I-MEASUREMENT       I-MEASUREMENT\n",
      "3l                       I-MEASUREMENT       I-MEASUREMENT\n",
      "nc                       I-MEASUREMENT       I-MEASUREMENT\n",
      "baseline                 I-MEASUREMENT       I-MEASUREMENT\n",
      "home                     B-DRUG              B-DRUG\n",
      "oxygen                   I-DRUG              B-DRUG\n",
      "<PAD>                    O                   O\n",
      "<PAD>                    O                   O\n",
      "<PAD>                    O                   O\n",
      "<PAD>                    O                   O\n",
      "<PAD>                    O                   O\n",
      "<PAD>                    O                   O\n",
      "<PAD>                    O                   O\n",
      "<PAD>                    O                   O\n",
      "<PAD>                    O                   O\n",
      "<PAD>                    O                   O\n",
      "<PAD>                    O                   O\n",
      "<PAD>                    O                   O\n",
      "<PAD>                    O                   O\n",
      "<PAD>                    O                   O\n",
      "<PAD>                    O                   O\n",
      "<PAD>                    O                   O\n",
      "<PAD>                    O                   O\n",
      "<PAD>                    O                   O\n",
      "<PAD>                    O                   O\n",
      "<PAD>                    O                   O\n",
      "<PAD>                    O                   O\n",
      "<PAD>                    O                   O\n",
      "<PAD>                    O                   O\n",
      "<PAD>                    O                   O\n",
      "<PAD>                    O                   O\n"
     ]
    }
   ],
   "source": [
    "generate_sample(x,y,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_ids_to_tags(preds,tag_ids):\n",
    "    id_to_tags = get_id_mappings(tag_ids)\n",
    "\n",
    "    tag_seqs = []\n",
    "    for seq in preds:\n",
    "        tag_seqs.append([id_to_tags[str(i)] for i in seq])\n",
    "    return tag_seqs\n",
    "\n",
    "def get_real_labels(model,x_test,y_test,tag_ids):\n",
    "    test_preds = np.argmax(model.predict(x_test),axis=-1)\n",
    "    true_vals = np.argmax(y_test,axis=-1)\n",
    "    test_preds = transform_ids_to_tags(test_preds,tag_ids)\n",
    "    true_vals = transform_ids_to_tags(true_vals,tag_ids)\n",
    "    return true_vals,test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "CONDITION/SYMPTOM       0.46      0.43      0.44       300\n",
      "             DRUG       0.65      0.55      0.59        86\n",
      "         LOCATION       0.64      0.75      0.69       102\n",
      "      MEASUREMENT       0.35      0.40      0.37        65\n",
      "            EVENT       0.25      0.54      0.35       120\n",
      "             TIME       0.28      0.36      0.31        36\n",
      "     ORGANIZATION       0.57      0.31      0.40        13\n",
      "           GENDER       0.62      0.89      0.73         9\n",
      "           AMOUNT       0.40      0.33      0.37        63\n",
      "              AGE       0.53      0.53      0.53        15\n",
      "        FREQUENCY       0.00      0.00      0.00        12\n",
      "\n",
      "        micro avg       0.42      0.48      0.45       821\n",
      "        macro avg       0.45      0.48      0.46       821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "true_vals,test_preds = get_real_labels(model,x_test,y_test,tag_ids)\n",
    "report = classification_report(true_vals,test_preds)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.4521640091116173\n"
     ]
    }
   ],
   "source": [
    "model_f1 = f1_score(true_vals,test_preds)\n",
    "print(\"F1-Score:\",model_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model sets the baseline of NER prediction with an F1-Score of ~0.45. Next results are saved for comparison to later models such as CRFs and other word embedding methods.\n",
    "\n",
    "### 9. Saving Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(x)\n",
    "model_desc = f\"BiLSTM-EmbedSize-{embedding_size}\"\n",
    "results_file = \"./nlp_data/model_results.csv\"\n",
    "note = \"Simple BiLSTM Max Sequence Len of 50\"\n",
    "def append_model_results(model_f1,n_samples,model_desc,file,note):\n",
    "    with open(file,'a') as f:\n",
    "        results = f\"\\n{model_f1},{n_samples},{model_desc},{time.ctime()},{note}\"\n",
    "        f.writelines(results)\n",
    "    print(\"~~~Results Successfully Saved\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~Results Successfully Saved\n"
     ]
    }
   ],
   "source": [
    "append_model_results(model_f1,n_samples,model_desc,results_file,note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>N-Samples</th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Date</th>\n",
       "      <th>Note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.606472</td>\n",
       "      <td>2592.0</td>\n",
       "      <td>BiLSTM-Word2Vec-EmbedSize-100</td>\n",
       "      <td>Thu Nov  7 13:30:51 2019</td>\n",
       "      <td>Used Custom Word2Vec Embeddings of entire Disc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.622917</td>\n",
       "      <td>2592.0</td>\n",
       "      <td>BiLSTM-Word2Vec-EmbedSize-100</td>\n",
       "      <td>Thu Nov  7 13:46:03 2019</td>\n",
       "      <td>Used Custom Word2Vec Embeddings of entire Disc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.545845</td>\n",
       "      <td>2592.0</td>\n",
       "      <td>BiLSTM-Glove-EmbedSize-100</td>\n",
       "      <td>Thu Nov  7 14:34:22 2019</td>\n",
       "      <td>Max Len Reverted Back to 50 Words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.622508</td>\n",
       "      <td>2592.0</td>\n",
       "      <td>CRF</td>\n",
       "      <td>Thu Nov  7 14:41:08 2019</td>\n",
       "      <td>Simple CRF model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.452164</td>\n",
       "      <td>2592.0</td>\n",
       "      <td>BiLSTM-EmbedSize-100</td>\n",
       "      <td>Thu Nov  7 15:01:08 2019</td>\n",
       "      <td>Simple BiLSTM Max Sequence Len of 50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    F1-Score  N-Samples                     Model Type  \\\n",
       "14  0.606472     2592.0  BiLSTM-Word2Vec-EmbedSize-100   \n",
       "15  0.622917     2592.0  BiLSTM-Word2Vec-EmbedSize-100   \n",
       "16  0.545845     2592.0     BiLSTM-Glove-EmbedSize-100   \n",
       "17  0.622508     2592.0                            CRF   \n",
       "18  0.452164     2592.0           BiLSTM-EmbedSize-100   \n",
       "\n",
       "                        Date  \\\n",
       "14  Thu Nov  7 13:30:51 2019   \n",
       "15  Thu Nov  7 13:46:03 2019   \n",
       "16  Thu Nov  7 14:34:22 2019   \n",
       "17  Thu Nov  7 14:41:08 2019   \n",
       "18  Thu Nov  7 15:01:08 2019   \n",
       "\n",
       "                                                 Note  \n",
       "14  Used Custom Word2Vec Embeddings of entire Disc...  \n",
       "15  Used Custom Word2Vec Embeddings of entire Disc...  \n",
       "16                  Max Len Reverted Back to 50 Words  \n",
       "17                                   Simple CRF model  \n",
       "18               Simple BiLSTM Max Sequence Len of 50  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(results_file).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras36]",
   "language": "python",
   "name": "conda-env-keras36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
