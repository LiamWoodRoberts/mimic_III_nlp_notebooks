{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a CRF with DataTurks Annotated .tsv File."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from seqeval.metrics import f1_score,classification_report\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional,Input,concatenate,SpatialDropout1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import pos_tag\n",
    "import eli5\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "from sklearn_crfsuite.metrics import flat_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting Data to Sequences\n",
    "\n",
    "### Contents:\n",
    "\n",
    "1. Reading File and formatting as sequences\n",
    "2. Formatting Entities to IOB Scheme\n",
    "3. Adding POS and Other CRF Features\n",
    "4. Train Test Split\n",
    "5. Training Model\n",
    "6. Evaluating Model Preformance\n",
    "7. Saving Model Results\n",
    "\n",
    "### 1. Reading and Formatting File:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_turks(file):\n",
    "    with open(file) as f:\n",
    "        lines = [i.rstrip().split(\"\\t\") for i in f.readlines()]\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = \"./data/Medical NER V2 2000.tsv\"\n",
    "word_ents = read_turks(file)\n",
    "word_ents[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_words(word_ents):\n",
    "    '''removes quote and comma characters from'''\n",
    "    new_word_ents = []\n",
    "    for ents in word_ents:\n",
    "        word = ents[0]\n",
    "        word = word.replace('\"','')\n",
    "        ents[0] = word\n",
    "        new_word_ents.append(ents)\n",
    "    return new_word_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ents = clean_words(word_ents)\n",
    "new_ents[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seqs(word_ents):\n",
    "    seqs = []\n",
    "    seq = []\n",
    "    for ents in word_ents:\n",
    "        if len(ents)>1:\n",
    "            if len(ents[0])>0:\n",
    "                if ents[0][-1] == \".\":\n",
    "                    seq.append([ents[0][:-1],ents[1]])\n",
    "                else:\n",
    "                    seq.append(ents)\n",
    "        else:\n",
    "            seqs.append(seq)\n",
    "            seq=[]\n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seqs = create_seqs(new_ents)\n",
    "seqs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_word(ent):\n",
    "    '''Splits at specified special characters keeping special characters as their own value'''\n",
    "    words = re.split('([/\\-\\%><])',ent[0])\n",
    "    return [[i,ent[1]] for i in words if len(i)>0]\n",
    "\n",
    "def expand_special_chars(seqs):\n",
    "    '''Expands special characters in words into seperate words while '''\n",
    "    new_seqs = []\n",
    "    for seq in seqs:\n",
    "        new_seq = []\n",
    "        for word in seq:\n",
    "            new_seq += expand_word(word)\n",
    "        new_seqs.append(new_seq)\n",
    "    return new_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_seqs = expand_special_chars(seqs)\n",
    "ex_seqs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Common Numeric Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_numerics(seq):\n",
    "    '''Add encodings for common number types'''\n",
    "    enc_seq = []\n",
    "    for ent in seq:\n",
    "        enc = ent[0].strip()\n",
    "        if re.match(\"^\\d$\",ent[0]) != None:\n",
    "            enc = \"<1DigitNum>\"\n",
    "        elif re.match(\"^\\d\\d$\",ent[0]) != None:\n",
    "            enc = \"<2DigitNum>\"\n",
    "        elif re.match(\"^\\d\\d\\d$\",ent[0]) !=None:\n",
    "            enc = \"<3DigitNum>\"\n",
    "        elif re.match(\"^\\d{4}$\",ent[0]) != None:\n",
    "            enc = \"4DigitNum\"\n",
    "        elif re.match(\"^\\d*\\.\\d*$\",ent[0]) != None:\n",
    "            enc = \"<DecimalNum>\"\n",
    "        elif re.match(\"^\\d+,\\d+$\",ent[0]) != None:\n",
    "            enc = \"<CommaNum>\"\n",
    "        elif re.match(\"^\\d+'?s$\",ent[0]) !=None:\n",
    "            enc = \"<RangeNum>\"\n",
    "            \n",
    "        enc_seq.append([enc,ent[1]])\n",
    "    return enc_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_seqs = [encode_numerics(seq) for seq in ex_seqs]\n",
    "enc_seqs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Formatting Entities to IOB (Inside,Outside, Beginning) Scheme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tags(word_ents):\n",
    "    '''adds IOB scheme to tags'''\n",
    "    new_ents = []\n",
    "    for i in range(0,len(word_ents)):\n",
    "        if word_ents[i][1] == \"O\":\n",
    "            tag = word_ents[i][1]\n",
    "        else:\n",
    "            if not i:\n",
    "                tag = \"B-\"+word_ents[i][1]\n",
    "            else:\n",
    "                if (word_ents[i][1] != word_ents[i-1][1]):\n",
    "                    tag = \"B-\"+word_ents[i][1]\n",
    "                else:\n",
    "                    tag = \"I-\"+word_ents[i][1]\n",
    "\n",
    "        new_ents.append([word_ents[i][0],tag])\n",
    "    return new_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tag_seqs = [clean_tags(ents) for ents in enc_seqs]\n",
    "cleaned_tag_seqs[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Adding POS and Other CRF Specific Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pos(seqs):\n",
    "    new_seqs = []\n",
    "    for sentance in seqs:\n",
    "        words = [word[0] for word in sentance]\n",
    "        pos = pos_tag(words)        \n",
    "        new_seq = [pos[i]+(sentance[i][1],) for i in range(len(sentance))]\n",
    "        new_seqs.append(new_seq)\n",
    "    return new_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_seqs = add_pos(cleaned_tag_seqs)\n",
    "print(pos_seqs[0])\n",
    "print(len(pos_seqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    '''\n",
    "    \n",
    "    From:\n",
    "    https://www.depends-on-the-definition.com/named-entity-recognition-conditional-random-fields-python/\n",
    "    \n",
    "    '''\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [sent2features(s) for s in pos_seqs]\n",
    "y = [sent2labels(s) for s in pos_seqs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = CRF(algorithm='lbfgs',\n",
    "          c1=0.1,\n",
    "          c2=0.1,\n",
    "          max_iterations=100,\n",
    "          all_possible_transitions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf.fit(x_train, y_train)\n",
    "pred = crf.predict(x_test)\n",
    "tr_pred = crf.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test,pred)\n",
    "print(\"Test Results:\\n\",\"-\"*60)\n",
    "print(report)\n",
    "print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_report = classification_report(y_train,tr_pred)\n",
    "print(\"Train Results:\\n\",\"-\"*60)\n",
    "print(tr_report)\n",
    "print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see some of the weights used by the CRF in determining label classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eli5.show_weights(crf,top=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_f1 = f1_score(y_test,pred)\n",
    "print(\"F1-Score:\",model_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model yields a respectable F1-Score compared to the other models. Only the BiLSTM with Custom Word2Vec Embeddings is able to outperform it and it does so only marginally.\n",
    "\n",
    "### 7. Saving Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(x)\n",
    "model_desc = f\"CRF\"\n",
    "results_file = \"./data/model_results.csv\"\n",
    "note = '''Simple CRF model with same encodings as Word2Vec Models'''\n",
    "def append_model_results(model_f1,n_samples,model_desc,file,note):\n",
    "    with open(file,'a') as f:\n",
    "        results = f\"\\n{model_f1},{int(n_samples)},{model_desc},{time.ctime()},{note}\"\n",
    "        f.writelines(results)\n",
    "    print(\"~~~Results Successfully Saved\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_model_results(model_f1,n_samples,model_desc,results_file,note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(results_file).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras36]",
   "language": "python",
   "name": "conda-env-keras36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
